# Iteração {#sec-iteration}

```{r}
#| echo: false
#| results: asis

source("_common.R")

```

## Introdução

Neste capítulo, você aprenderá ferramentas para iteração, executando repetidamente a mesma ação em objetos diferentes.
A iteração em R geralmente tende a parecer bastante diferente de outras linguagens de programação porque grande parte dela está implícita e a obtemos "de graça".
Por exemplo, se você deseja duplicar um vetor numérico `x` no R, você pode simplesmente escrever `2 * x`.
Na maioria das outras linguagens, você precisaria duplicar explicitamente cada elemento de `x` usando algum tipo de laço *for* (*for loop*).

Este livro já lhe deu um pequeno, mas poderoso número de ferramentas que executam a mesma ação para múltiplas “coisas”:

-   `facet_wrap()` e `facet_grid()` desenham um gráfico para cada subconjunto.
-   `group_by()` junto com `summarize()` calcula estatísticas resumo para cada subconjunto.
-   `unnest_wider()` e `unnest_longer()` criam novas linhas e colunas para cada elemento de uma colunas-lista (*list-column*).

Agora é hora de aprender algumas ferramentas mais gerais, geralmente chamadas de ferramentas de **programação funcional** (*functional programming*) porque são construídas em torno de funções que recebem outras funções como entradas.
Aprender programação funcional pode facilmente se tornar bastante abstrato, mas neste capítulo manteremos as coisas concretas, concentrando-nos em três tarefas comuns: modificar múltiplas colunas, ler vários arquivos e salvar vários objetos.

### Pré-requisitos

Neste capítulo, focaremos nas ferramentas fornecidas pelos pacotes dplyr e purrr, ambos membros centrais do tidyverse.
Você já viu o dplyr antes, mas o [purrr](http://purrr.tidyverse.org/) é novo.
Usaremos apenas algumas funções do purrr neste capítulo, mas é um ótimo pacote para explorar à medida que você aprimora suas habilidades de programação.
Usaremos também o pacote `dados` e seu conjunto de dados `diamante`.

```{r}
#| label: setup
#| message: false

library(tidyverse)
library(dados)
```

## Modificando múltiplas colunas {#sec-across}

Imagine que você tem esse *tibble* simples e deseja contar o número de observações e calcular a mediana de cada coluna.

```{r}
df <- tibble(
  a = rnorm(10),
  b = rnorm(10),
  c = rnorm(10),
  d = rnorm(10)
)
```

Você poderia fazer isso copiando e colando:

```{r}
df |> summarize(
  n = n(),
  a = median(a),
  b = median(b),
  c = median(c),
  d = median(d),
)
```

Isso quebra nossa regra geral de nunca copiar e colar mais de duas vezes, e você pode imaginar que isso será muito tedioso se você tiver dezenas ou até centenas de colunas.
Em vez disso, você pode usar a função `across()`:

```{r}
df |> summarize(
  n = n(),
  across(a:d, median),
)
```

`across()` tem três argumentos particularmente importantes, que discutiremos em detalhes nas seções seguintes.
Você usará os dois primeiros sempre que usar `across()`: o primeiro argumento, `.cols`, especifica quais colunas você deseja iterar, e o segundo argumento, `.fns`, especifica o que fazer com cada coluna.
Você pode usar o argumento `.names` quando precisar de controle adicional sobre os nomes das colunas de saída, o que é particularmente importante quando você usa `across()` com `mutate()`.
Também discutiremos duas variações importantes, `if_any()` e `if_all()`, que funcionam com `filter()`.

### Selecionando colunas com `.cols`

O primeiro argumento para `across()`, `.cols`, seleciona as colunas a serem transformadas.
Isso usa as mesmas especificações de `select()`, @sec-select, então você pode usar funções como `starts_with()` e `ends_with()` para selecionar colunas com base em seus nomes.

Existem duas técnicas de seleção adicionais que são particularmente úteis para `across()`: `everything()` e `where()`.
`everything()` (*tudo/todas* em inglês) é direto ao ponto: seleciona todas as colunas (não agrupadas):

```{r}
df <- tibble(
  grp = sample(2, 10, replace = TRUE),
  a = rnorm(10),
  b = rnorm(10),
  c = rnorm(10),
  d = rnorm(10)
)

df |> 
  group_by(grp) |> 
  summarize(across(everything(), median))
```

Observe que as colunas de agrupamento (`grp` aqui) não estão incluídas em `across()`, porque são preservadas automaticamente por `summarize()`.

`where()` permite selecionar colunas com base em seu tipo:

-   `where(is.numeric)` seleciona todas as colunas numéricas.
-   `where(is.character)` seleciona todas as colunas de *string*.
-   `where(is.Date)` seleciona todas as colunas de data.
-   `where(is.POSIXct)` seleciona todas as colunas de data e horário (*date-time*).
-   `where(is.logical)` seleciona todas as colunas lógicas.

Assim como outros seletores, você pode combiná-los com álgebra booleana.
Por exemplo, `!where(is.numeric)` seleciona todas as colunas não numéricas e `starts_with("a") & where(is.logical)` seleciona todas as colunas lógicas cujo nome começa com "a".

### Chamando uma única função

O segundo argumento para `across()` define como cada coluna será transformada.
Em casos simples, como acima, esta será uma única função existente.
Este é um recurso muito especial do R: estamos passando uma função (`median`, `mean`, `str_flatten`, ...) para outra função (`across`).
Esta é uma das características que torna R uma linguagem de programação funcional.

É importante notar que estamos passando esta função para `across()`, então `across()` pode chamá-la; não a estamos chamando nós mesmos.
Isso significa que o nome da função nunca deve ser seguido por `()`.
Se você esquecer, receberá um erro:

```{r}
#| error: true
df |> 
  group_by(grp) |> 
  summarize(across(everything(), median()))
```

Este erro surge porque você está chamando a função sem entrada, por exemplo:

```{r}
#| error: true
median()
```

### Chamando múltiplas funções

Em casos mais complexos, talvez você queira fornecer argumentos adicionais ou executar diversas transformações.
Vamos motivar este problema com um exemplo simples: o que acontece se tivermos alguns valores faltantes (*missing values*) em nossos dados?
`median()` propaga esses valores ausentes, fornecendo um resultado não ideal:

```{r}
rnorm_na <- function(n, n_na, mean = 0, sd = 1) {
  sample(c(rnorm(n - n_na, mean = mean, sd = sd), rep(NA, n_na)))
}

df_faltantes <- tibble(
  a = rnorm_na(5, 1),
  b = rnorm_na(5, 1),
  c = rnorm_na(5, 2),
  d = rnorm(5)
)
df_faltantes |> 
  summarize(
    across(a:d, median),
    n = n()
  )
```

Seria bom se pudéssemos passar `na.rm = TRUE` para `median()` para remover esses valores ausentes.
Para fazer isso, em vez de chamar `median()` diretamente, precisamos criar uma nova função que chame `median()` com os argumentos desejados:

```{r}
df_faltantes |> 
  summarize(
    across(a:d, function(x) median(x, na.rm = TRUE)),
    n = n()
  )
```

Isso é um tanto detalhado ou longo demais, então R vem com um atalho útil: para esse tipo de função descartável, ou **anônima**[^iteration-1], você pode substituir `function` por `\` [^iteration-2]
:

[^iteration-1]: Ela é anônima, porque nunca lhe demos explicitamente um nome com `<-`.
    Outro termo que os programadores usam para isso é “função lambda”.

[^iteration-2]: Em códigos mais antigos, você pode ver uma sintaxe semelhante a `~ .x + 1`.
    Esta é outra maneira de escrever funções anônimas, mas só funciona dentro de funções tidyverse e sempre usa o nome da variável `.x`.
    Agora recomendamos a sintaxe base, `\(x) x + 1`.

```{r}
#| results: false
df_faltantes |> 
  summarize(
    across(a:d, \(x) median(x, na.rm = TRUE)),
    n = n()
  )
```

Em ambos os casos, `across()` efetivamente se expande para o código a seguir:

```{r}
#| eval: false

df_faltantes |> 
  summarize(
    a = median(a, na.rm = TRUE),
    b = median(b, na.rm = TRUE),
    c = median(c, na.rm = TRUE),
    d = median(d, na.rm = TRUE),
    n = n()
  )
```

Quando removemos os valores ausentes de `median()`, seria bom saber quantos valores foram removidos.
Podemos descobrir isso fornecendo duas funções para `across()`: uma para calcular a mediana e outra para contar os valores faltantes.
Você fornece múltiplas funções usando uma lista nomeada (*named-list*) para `.fns`:

```{r}
df_faltantes |> 
  summarize(
    across(a:d, list(
      mediana = \(x) median(x, na.rm = TRUE),
      n_faltante = \(x) sum(is.na(x))
    )),
    n = n()
  )
```

Se você olhar com atenção, poderá intuir que as colunas são nomeadas usando uma especificação da função glue (@sec-glue) como `{.col}_{.fn}` onde `.col` é o nome da coluna original e `. fn` é o nome da função.
Isso não é uma coincidência!
Como você aprenderá na próxima seção, você pode usar o argumento `.names` para fornecer sua própria especificação da função *glue*.

### Nomes de colunas

O resultado de `across()` é nomeado de acordo com a especificação fornecida no argumento `.names`.
Poderíamos especificar o nosso próprio argumento se quiséssemos que o nome da função viesse primeiro[^iteration-3]:

[^iteration-3]: Atualmente, você não pode alterar a ordem das colunas, mas pode reordená-las posteriormente usando `relocate()` ou similar.

```{r}
df_faltantes |> 
  summarize(
    across(
      a:d,
      list(
        mediana = \(x) median(x, na.rm = TRUE),
        n_faltante= \(x) sum(is.na(x))
      ),
      .names = "{.fn}_{.col}"
    ),
    n = n(),
  )
```

O argumento `.names` é particularmente importante quando você usa `across()` com `mutate()`.
Por padrão, a saída de `across()` recebe os mesmos nomes das entradas.
Isso significa que `across()` dentro de `mutate()` substituirá as colunas existentes.
Por exemplo, aqui usamos `coalesce()` para substituir `NA`s por `0`:

```{r}
df_faltantes |> 
  mutate(
    across(a:d, \(x) coalesce(x, 0))
  )
```

Se você quiser criar novas colunas, você pode usar o argumento `.names` para dar novos nomes à saída:

```{r}
df_faltantes |> 
  mutate(
    across(a:d, \(x) coalesce(x, 0), .names = "{.col}_na_zero")
  )
```

### Filtrando

`across()` é uma ótima combinação para `summarize()` e `mutate()` mas é mais estranho de usar com `filter()`, porque você normalmente combina múltiplas condições com `|` ou `&`.
É claro que `across()` pode ajudar a criar múltiplas colunas lógicas, mas e depois?
Por isso, dplyr fornece duas variantes de `across()` chamadas `if_any()` e `if_all()`:

```{r}
# o mesmo que df_faltantes |> filter(is.na(a) | is.na(b) | is.na(c) | is.na(d))
df_faltantes |> filter(if_any(a:d, is.na))

# o mesmo que df_faltantes |> filter(is.na(a) & is.na(b) & is.na(c) & is.na(d))
df_faltantes |> filter(if_all(a:d, is.na))
```

### `across()` em funções

`across()` é particularmente útil para programar porque permite operar em múltiplas colunas.
Por exemplo, [Jacob Scott](https://twitter.com/_wurli/status/1571836746899283969) usa esta pequena função auxiliar que agrega um monte de funções do pacote lubridate para expandir todas as colunas de data em colunas de ano, mês e dia:

```{r}
expande_datas <- function(df) {
  df |> 
    mutate(
      across(where(is.Date), list(ano = year, mes = month, dia = mday))
    )
}

df_data <- tibble(
  nome = c("Amy", "Bob"),
  data = ymd(c("2009-08-03", "2010-01-16"))
)

df_data |> 
  expande_datas()
```

`across()` também facilita o fornecimento de múltiplas colunas em um único argumento porque o primeiro argumento usa seleção organizada (*tidy-selection*); você só precisa se lembrar de abraçar (*embrace*) esse argumento, conforme discutimos no @sec-abracing.
Por exemplo, esta função calculará as médias das colunas numéricas por padrão.
Mas ao fornecer o segundo argumento você pode optar por sumarizar apenas as colunas selecionadas:

```{r}
summariza_medias <- function(df, summary_vars = where(is.numeric)) {
  df |> 
    summarize(
      across({{ summary_vars }}, \(x) mean(x, na.rm = TRUE)),
      n = n(),
      .groups = "drop"
    )
}
diamante |> 
  group_by(corte) |> 
  summariza_medias()

diamante |> 
  group_by(corte) |> 
  summariza_medias(c(quilate, x:z))
```

### Vs `pivot_longer()`

Antes de continuarmos, vale a pena apontar uma conexão interessante entre `across()` e `pivot_longer()` (@sec-pivoting).
Em muitos casos, você realiza os mesmos cálculos primeiro pivotando (*pivoting*) os dados e depois executando as operações por grupo em vez de por coluna.
Por exemplo, veja esta sumarização multifuncional:

```{r}
df |> 
  summarize(across(a:d, list(mediana = median, media = mean)))
```

Poderíamos calcular os mesmos valores pivoteando por comprimento (*pivoting longer*) e sumarizando:

```{r}
longo <- df |> 
  pivot_longer(a:d) |> 
  group_by(name) |> 
  summarize(
    mediana = median(value),
    media = mean(value)
  )
longo
```

E se você quisesse a mesma estrutura de `across()` você poderia pivotear novamente:

```{r}
longo |> 
  pivot_wider(
    names_from = name,
    values_from = c(mediana, media),
    names_vary = "slowest",
    names_glue = "{name}_{.value}"
  )
```

Esta é uma técnica útil para conhecer porque às vezes você encontrará um problema que atualmente não é possível resolver com `across()`: quando você tem grupos de colunas com os quais você deseja realizar cálculos simultaneamente.
Por exemplo, imagine que nosso *data frame* contém valores e pesos e queremos calcular uma média ponderada:

```{r}
df_pareado <- tibble(
  a_val = rnorm(10),
  a_pesos = runif(10),
  b_val = rnorm(10),
  b_pesos = runif(10),
  c_val = rnorm(10),
  c_pesos = runif(10),
  d_val = rnorm(10),
  d_pesos = runif(10)
)
```

Atualmente, não há como fazer isso com `across()`[^iteration-4], mas é relativamente simples com `pivot_longer()`:

[^iteration-4]: Talvez haja um dia, mas atualmente não vemos como.

```{r}
df_longo <- df_pareado |> 
  pivot_longer(
    everything(), 
    names_to = c("grupo", ".value"), 
    names_sep = "_"
  )
df_longo

df_longo |> 
  group_by(grupo) |> 
  summarize(media = weighted.mean(val, pesos))
```

Se necessário, você poderia usar a `pivot_wider()` e voltar ao formato original.

### Exercícios

1.  Pratique suas habilidades na função `across()`:

    1.  Calculando o número de valores únicos em cada coluna de `dados::pinguins`.

    2.  Calculando a média de cada coluna em `dados::mtcarros`.

    3.  Agrupando `diamante` por `corte`, `transparencia` e `cor`, contando o número de observações e calculando a média de cada coluna numérica

2.  O que acontece se você usar uma lista de funções em `across()`, mas não as nomear?
    Como a saída é nomeada?

3.  Ajuste `expand_dates()` para remover automaticamente as colunas de data após elas terem sido expandidas.
    Você precisa adotar algum argumento?

4.  Explique o que cada etapa do *pipeline* faz nesta função.
    De qual recurso especial de `where()` estamos nos aproveitando?

    ```{r}
    #| results: false

    mostra_faltantes <- function(df, grupo_vars, sumariza_vars = everything()) {
      df |> 
        group_by(pick({{ grupo_vars }})) |> 
        summarize(
          across({{ sumariza_vars }}, \(x) sum(is.na(x))),
          .groups = "drop"
        ) |>
        select(where(\(x) any(x > 0)))
    }
    dados::voos |> mostra_faltantes(c(ano, mes, dia))
    ```

## Lendo múltiplos arquivos

Na seção anterior, você aprendeu como usar `dplyr::across()` para repetir uma transformação em múltiplas colunas.
Nesta seção, você aprenderá como usar `purrr::map()` para fazer algo em cada arquivo em um diretório.
Vamos começar com um pouco de motivação: imagine que você tem um diretório cheio de planilhas do Excel[^iteration-5] que deseja ler.
Você poderia fazer isso copiando e colando:

[^iteration-5]: Se você tivesse um diretório de arquivos csv com o mesmo formato, você pode usar a técnica do @sec-readr-directory.

```{r}
#| eval: false
dado2019 <- readxl::read_excel("data/y2019.xlsx")
dado2020 <- readxl::read_excel("data/y2020.xlsx")
dado2021 <- readxl::read_excel("data/y2021.xlsx")
dado2022 <- readxl::read_excel("data/y2022.xlsx")
```

E então use a `dplyr::bind_rows()` para combiná-los todos juntos:

```{r}
#| eval: false
dados_todos <- bind_rows(dados2019, dados2020, dados2021, dados2022)
```

Você pode imaginar que isso se tornaria entediante rapidamente, especialmente se você tivesse centenas de arquivos, não apenas quatro.
As seções a seguir mostram como automatizar esse tipo de tarefa.
Existem três etapas básicas: use `list.files()` para listar todos os arquivos em um diretório, depois use `purrr::map()` para ler cada um deles em uma lista e, em seguida, use `purrr::list_rbind( )` para combiná-los em um único *data frame*.
Discutiremos então como você pode lidar com situações de crescente heterogeneidade, onde não é possível fazer exatamente a mesma coisa com todos os arquivos.

### Listando arquivos do diretório

Como o nome sugere, `list.files()` lista os arquivos em um diretório.
Você quase sempre usará três argumentos:

-   O primeiro argumento, `path`, é o diretório onde procurar.

-   `pattern` é uma expressão regular usada para filtrar os nomes dos arquivos.
    O padrão mais comum é algo como `[.]xlsx$` ou `[.]csv$` para encontrar todos os arquivos com uma extensão especificada.

-   `full.names` determina se o nome do diretório deve ou não ser incluído na saída.
    Você quase sempre quer que isso seja `TRUE`.

Para tornar nosso exemplo motivador mais concreto, este livro contém uma pasta com 12 planilhas Excel contendo dados do pacote gapminder.
Cada arquivo contém dados referentes a um ano para 142 países.
Podemos listá-los todos com a chamada apropriada para `list.files()`:

```{r}
caminhos <- list.files("data/gapminder", pattern = "[.]xlsx$", full.names = TRUE)
caminhos
```

### Listas

Agora que temos esses 12 arquivos, poderíamos chamar `read_excel()` 12 vezes para obter 12 *data frames*:

```{r}
#| eval: false
gapminder_1952 <- readxl::read_excel("data/gapminder/1952.xlsx")
gapminder_1957 <- readxl::read_excel("data/gapminder/1957.xlsx")
gapminder_1962 <- readxl::read_excel("data/gapminder/1962.xlsx")
 ...,
gapminder_2007 <- readxl::read_excel("data/gapminder/2007.xlsx")
```

Entretanto, colocar cada planilha em sua própria variável vai dificultar o trabalho com elas alguns passos adiante.
Em vez disso, será mais fácil trabalhar com elas se as colocarmos em um único objeto.
Uma lista é a ferramenta perfeita para este trabalho:

```{r}
#| eval: false
arquivos <- list(
  readxl::read_excel("data/gapminder/1952.xlsx"),
  readxl::read_excel("data/gapminder/1957.xlsx"),
  readxl::read_excel("data/gapminder/1962.xlsx"),
  ...,
  readxl::read_excel("data/gapminder/2007.xlsx")
)
```

```{r}
#| include: false
arquivos <- map(caminhos, readxl::read_excel)
```

Agora que você tem esses *data frames* em uma lista, como retirar algum deles?
Você pode usar `arquivos[[i]]` para extrair o i<sup>ésimo</sup> elemento:

```{r}
arquivos[[3]]
```

Voltaremos a ver `[[` com mais detalhes no @sec-subset-one.

### `purrr::map()` e `list_rbind()`

O código para coletar esses *data frames* de uma lista "manualmente" é basicamente tão tedioso de digitar quanto o código que lê os arquivos um por um.
Felizmente, podemos usar `purrr::map()` para fazer uso ainda melhor do nosso vetor `caminhos` (*paths*).
`map()` é semelhante a`across()`, mas em vez de fazer algo em cada coluna em um *data frame*, ele faz algo em cada elemento de um vetor.`map(x, f)` é uma abreviação de:

```{r}
#| eval: false
list(
  f(x[[1]]),
  f(x[[2]]),
  ...,
  f(x[[n]])
)
```

Portanto, podemos usar `map()` para obter uma lista de 12 *data frames*:

```{r}
arquivos <- map(caminhos, readxl::read_excel)
length(arquivos)

arquivos[[1]]
```

(Esta é outra estrutura de dados que não é exibida de forma particularmente compacta com `str()`, então você pode querer carregá-la no RStudio e inspecioná-la com `View()`).

Agora podemos usar `purrr::list_rbind()` para combinar essa lista de *data frames* em um único *data frame*:

```{r}
list_rbind(arquivos)
```

Ou poderíamos executar as duas etapas ao mesmo tempo em um *pipeline*:

```{r}
#| results: false
caminhos |> 
  map(readxl::read_excel) |> 
  list_rbind()
```

E se quisermos passar argumentos extras para `read_excel()`?
Usamos a mesma técnica que usamos com `across()`.
Por exemplo, muitas vezes é útil olhar as primeiras linhas dos dados com `n_max = 1`:

```{r}
caminhos |> 
  map(\(caminhos) readxl::read_excel(caminhos, n_max = 1)) |> 
  list_rbind()
```

Isso deixa claro que algo está faltando: não há coluna `ano` porque esse valor está registrado no caminho (*path*), não nos arquivos individuais.
Abordaremos esse problema a seguir.

### Dados no caminho {#sec-data-in-the-path}

Às vezes, o nome do arquivo é o próprio dado .
Neste exemplo, o nome do arquivo contém o ano, que não é registrado de outra forma nos arquivos individuais.
Para colocar essa coluna no *data frame* final, precisamos fazer duas coisas:

Primeiro, nomeamos o vetor de caminhos (*paths*).
A maneira mais fácil de fazer isso é com a função `set_names()`, que pode receber uma função.
Aqui usamos a `basename()` para extrair apenas o nome do arquivo do caminho completo:

```{r}
caminhos |> set_names(basename) 
```

Esses nomes são automaticamente transportados por todas as funções *map*, portanto a lista de *data frames* terá os mesmos nomes:

```{r}
arquivos <- caminhos |> 
  set_names(basename) |> 
  map(readxl::read_excel)
```

Isso faz com que esta chamada para `map()` seja uma abreviação para:

```{r}
#| eval: false
arquivos <- list(
  "1952.xlsx" = readxl::read_excel("data/gapminder/1952.xlsx"),
  "1957.xlsx" = readxl::read_excel("data/gapminder/1957.xlsx"),
  "1962.xlsx" = readxl::read_excel("data/gapminder/1962.xlsx"),
  ...,
  "2007.xlsx" = readxl::read_excel("data/gapminder/2007.xlsx")
)
```

Você também pode usar `[[` para extrair elementos por nome:

```{r}
arquivos[["1962.xlsx"]]
```

Então usamos o argumento `names_to` da função `list_rbind()` para salvar os nomes em uma nova coluna chamada `ano` e então usamos `readr::parse_number()` para extrair o número da string.

```{r}
caminhos |> 
  set_names(basename) |> 
  map(readxl::read_excel) |> 
  list_rbind(names_to = "ano") |> 
  mutate(ano = parse_number(ano))
```

Em casos mais complicados, pode haver outras variáveis ​​armazenadas no nome do diretório ou talvez o nome do arquivo contenha vários elementos de dados.
Nesse caso, use `set_names()` (sem quaisquer argumentos) para registrar o caminho (*path*) completo e, em seguida, use a função `tidyr::separate_wider_delim()` e similares para transformá-los em colunas úteis.

```{r}
caminhos |> 
  set_names() |> 
  map(readxl::read_excel) |> 
  list_rbind(names_to = "ano") |> 
  separate_wider_delim(ano, delim = "/", names = c(NA, "dir", "arquivo")) |> 
  separate_wider_delim(arquivo, delim = ".", names = c("arquivo", "ext"))
```

### Salve seu trabalho

Agora que você fez todo esse trabalho duro para chegar a um *data frame* bem organizado, é um ótimo momento para salvar seu trabalho:

```{r}
gapminder <- caminhos |> 
  set_names(basename) |> 
  map(readxl::read_excel) |> 
  list_rbind(names_to = "ano") |> 
  mutate(ano = parse_number(ano))

write_csv(gapminder, "gapminder.csv")
```

Agora, quando você voltar a esse problema no futuro, poderá ler um único arquivo csv.
Para conjuntos de dados grandes e mais ricos, usar parquet pode ser uma escolha melhor do que `.csv`, conforme discutido no @sec-parquet.

```{r}
#| include: false
unlink("gapminder.csv")
```

Se você estiver trabalhando em um projeto, sugerimos chamar o arquivo que faz esse tipo de trabalho de preparação de dados como `0-cleanup.R`.
O `0` no nome do arquivo sugere que ele deve ser executado antes de qualquer outra coisa.

Se seus arquivos de dados de entrada mudarem com o tempo, você pode considerar aprender uma ferramenta como [targets](https://docs.ropensci.org/targets/) para configurar seu código de limpeza de dados para ser executado automaticamente sempre que um dos arquivos de entrada arquivos são modificados.

### Muitas iterações simples

Aqui acabamos de carregar os dados diretamente do disco e tivemos a sorte de obter um conjunto de dados organizado (*tidy*).
Na maioria dos casos, você precisará fazer alguma limpeza adicional e terá duas opções básicas: fazer uma rodada de iteração com uma função complexa ou fazer várias rodadas de iteração com funções simples.
Em nossa experiência, a maioria das pessoas chega primeiro a uma iteração complexa, mas geralmente é melhor fazer várias iterações simples.

Por exemplo, imagine que você deseja ler vários arquivos, filtrar os valores ausentes, pivotear e depois combinar.
Uma maneira de abordar o problema é escrever uma função que pegue um arquivo e execute todas essas etapas e depois chame `map()` uma vez:

```{r}
#| eval: false
processa_arquivo <- function(caminho) {
  df <- read_csv(caminho)
  
  df |> 
    filter(!is.na(id)) |> 
    mutate(id = tolower(id)) |> 
    pivot_longer(jan:dez, names_to = "mes")
}

caminhos |> 
  map(processa_arquivo) |> 
  list_rbind()
```

Alternativamente, você poderia executar cada etapa de `processa_arquivo()` para cada arquivo:

```{r}
#| eval: false

caminhos |> 
  map(read_csv) |> 
  map(\(df) df |> filter(!is.na(id))) |> 
  map(\(df) df |> mutate(id = tolower(id))) |> 
  map(\(df) df |> pivot_longer(jan:dez, names_to = "mes")) |> 
  list_rbind()
```

Recomendamos essa abordagem porque ela evita que você fique obcecado em acertar o primeiro arquivo antes de passar para os demais.
Ao considerar todos os dados ao fazer a arrumação (*tidying*) e a limpeza, é mais provável que você pense de forma holística e obtenha um resultado de maior qualidade.

Neste exemplo específico, há outra otimização que você pode fazer, vinculando todos os *data frames* primeiro.
Então você pode confiar no comportamento normal do dplyr:

```{r}
#| eval: false
caminhos |> 
  map(read_csv) |> 
  list_rbind() |> 
  filter(!is.na(id)) |> 
  mutate(id = tolower(id)) |> 
  pivot_longer(jan:dez, names_to = "mes")
```

### Dados Heterogêneos

Infelizmente, às vezes não é possível ir de `map()` direto para `list_rbind()` porque os *data frames* são tão heterogêneos que `list_rbind()` falha ou resulta um *data frame* que não é muito útil.
Nesse caso, ainda é útil começar carregando todos os arquivos:

```{r}
#| eval: false
arquivos <- caminhos |> 
  map(readxl::read_excel) 
```

Então, uma estratégia muito útil é capturar a estrutura dos *data frames* para que você possa explorá-la usando suas habilidades em ciência de dados.
Uma maneira de fazer isso é com esta útil função `df_tipos` [^iteration-6] que retorna um *tibble* com uma linha para cada coluna:

[^iteration-6]: Não vamos explicar como ela funciona, mas se você olhar a documentação para as funções usadas, você conseguirá decifrá-la.

```{r}
df_tipos <- function(df) {
  tibble(
    nome_coluna = names(df), 
    tipo_coluna = map_chr(df, vctrs::vec_ptype_full),
    n_faltantes = map_int(df, \(x) sum(is.na(x)))
  )
}

df_tipos(dados_gapminder)
```

Você pode então aplicar esta função a todos os arquivos e talvez fazer alguma pivotagem para facilitar a visualização de onde estão as diferenças.
Por exemplo, isso facilita verificar se as planilhas do gapminder com as quais estamos trabalhando são bastante homogêneas:

```{r}
arquivos |> 
  map(df_tipos) |> 
  list_rbind(names_to = "arquivo") |> 
  select(-n_faltantes) |> 
  pivot_wider(names_from = nome_coluna, values_from = tipo_coluna)
```

Se os arquivos tiverem formatos heterogêneos, talvez seja necessário realizar mais processamento antes de mesclá-los com êxito.
Infelizmente, agora vamos deixar você descobrir isso sozinho, mas você pode querer ler sobre as funções `map_if()` e `map_at()`.
`map_if()` permite modificar seletivamente os elementos de uma lista com base em seus valores; `map_at()` permite modificar seletivamente elementos com base em seus nomes.

### Lidando com falhas

Às vezes, a estrutura dos seus dados pode ser tão estranha que você nem consegue ler todos os arquivos com um único comando.
E então você encontrará uma das desvantagens de `map()`: ele ou é bem-sucedido ou falha como um todo.
`map()` lerá com sucesso todos os arquivos em um diretório ou falhará com um erro, lendo zero arquivos.
Isso é irritante: por que uma falha impede você de acessar todos os outros sucessos?

Felizmente, purrr vem com um ajudante para resolver este problema: `possibly()`.
`possibly()` é conhecido como operador de função: ele pega uma função e retorna uma função com comportamento modificado.
Em particular, `possibly()` altera uma função de erro para retornar um valor que você especifica:

```{r}
arquivos <- caminhos |> 
  map(possibly(\(caminhos) readxl::read_excel(caminhos), NULL))

dados <- arquivos |> list_rbind()
```

Isso funciona particularmente bem aqui porque `list_rbind()`, como muitas funções do tidyverse, ignora automaticamente `NULL`s.

Agora você tem todos os dados que podem ser lidos facilmente e é hora de enfrentar a parte difícil de descobrir por que alguns arquivos falharam ao carregar e o que fazer a respeito.
Comece obtendo os caminhos que falharam:

```{r}
falhou <- map_vec(arquivos, is.null)
caminhos[falhou]
```

Em seguida, chame a função de importação novamente para cada falha e descubra o que deu errado.

## Salvando múltiplas saídas

Na última seção, você aprendeu sobre `map()`, que é útil para ler vários arquivos em um único objeto.
Nesta seção, exploraremos agora o problema oposto: como você pode pegar um ou mais objetos R e salvá-los em um ou mais arquivos?
Exploraremos esse desafio usando três exemplos:

-   Salvar vários *data frames* em um banco de dados.
-   Salvar vários *data frames* em vários arquivos `.csv`.
-   Salvando vários gráficos em vários arquivos `.png`.

### Gravando em um banco de dados {#sec-save-database}

Às vezes, ao trabalhar com muitos arquivos ao mesmo tempo, não é possível colocar todos os seus dados na memória de uma só vez e você não pode fazer `map(arquivos, read_csv)`.
Uma abordagem para lidar com esse problema é carregar seus dados em um banco de dados para que você possa acessar apenas os bits necessários com o dbplyr.

Se você tiver sorte, o pacote de banco de dados que você está usando fornecerá uma função útil que pega um vetor de caminhos e carrega todos eles no banco de dados.
Este é o caso do `duckdb_read_csv()` do duckdb:

```{r}
#| eval: false
con <- DBI::dbConnect(duckdb::duckdb())
duckdb::duckdb_read_csv(con, "gapminder", caminhos)
```

Isso funcionaria bem aqui, mas não temos arquivos csv, em vez disso temos planilhas do Excel.
Então teremos que fazer isso "manualmente".
Aprender a fazer isso manualmente também o ajudará quando você tiver vários csvs e o banco de dados com o qual está trabalhando não tiver uma função que carregue todos eles.

Precisamos começar criando uma tabela que será preenchida com dados.
A maneira mais fácil de fazer isso é criando um modelo, um *data frame* fictício que contém todas as colunas desejadas, mas apenas uma amostra dos dados.
Para os dados do gapminder, podemos fazer esse modelo lendo um único arquivo e adicionando o ano a ele:

```{r}
template <- readxl::read_excel(caminhos[[1]])
template$year <- 1952
template
```

Agora podemos nos conectar ao banco de dados e usar `DBI::dbCreateTable()` para transformar nosso modelo em uma tabela de banco de dados:

```{r}
con <- DBI::dbConnect(duckdb::duckdb())
DBI::dbCreateTable(con, "gapminder", template)
```

`dbCreateTable()` não usa os dados em `template`, apenas os nomes e tipos de variáveis.
Então se inspecionarmos a tabela `gapminder` agora você verá que ela está vazia mas tem as variáveis ​​que precisamos com os tipos que esperamos:

```{r}
con |> tbl("gapminder")
```

Em seguida, precisamos de uma função que pegue um único caminho de arquivo, leia-o em R e adicione o resultado à tabela `gapminder`.
Podemos fazer isso combinando `read_excel()` com `DBI::dbAppendTable()`:

```{r}
adiciona_arquivo <- function(caminho) {
  df <- readxl::read_excel(caminho)
  df$year <- parse_number(basename(caminho))
  
  DBI::dbAppendTable(con, "gapminder", df)
}
```

Agora precisamos chamar `adiciona_arquivo()` uma vez para cada elemento de `caminhos`.
Isso certamente é possível com `map()`:

```{r}
#| eval: false
caminhos |> map(adiciona_arquivo)
```

Mas não nos importamos com a saída de `adiciona_arquivo()`, então em vez de `map()` é ligeiramente melhor usar `walk()`.
`walk()` faz exatamente a mesma coisa que `map()` mas joga fora a saída:

```{r}
caminhos |> walk(adiciona_arquivo)
```

Agora podemos verificar se temos todos os dados na nossa tabela:

```{r}
con |> 
  tbl("gapminder") |> 
  count(year)
```

```{r}
#| include: false
DBI::dbDisconnect(con, shutdown = TRUE)
```

### Gravando arquivos csv

O mesmo princípio básico se aplica se quisermos escrever vários arquivos CSV, um para cada grupo.
Vamos imaginar que queremos pegar os dados do `dados::diamante` e salvar um arquivo csv para cada `transparencia`.
Primeiro, precisamos criar esses conjuntos de dados individuais.
Há muitas maneiras de fazer isso, mas há uma que gostamos particularmente: `group_nest()`.

```{r}
por_transparencia <- diamante |> 
  group_nest(transparencia)

por_transparencia
```

Isso nos dá um novo bloco com oito linhas e duas colunas.
`transparencia` é nossa variável de agrupamento e `data` é uma coluna-lista contendo um tibble para cada valor único de `transparencia`:

```{r}
por_transparencia$data[[1]]
```

Enquanto estamos aqui, vamos criar uma coluna que forneça o nome do arquivo de saída, usando `mutate()` e `str_glue()`:

```{r}
por_transparencia <- por_transparencia |> 
  mutate(caminho = str_glue("diamante-{transparencia}.csv"))

por_transparencia
```

Então, se quiséssemos salvar esses *data frames* manualmente, poderíamos escrever algo como:

```{r}
#| eval: false
write_csv(por_transparencia$data[[1]], por_transparencia$caminho[[1]])
write_csv(por_transparencia$data[[2]], por_transparencia$caminho[[2]])
write_csv(por_transparencia$data[[3]], por_transparencia$caminho[[3]])
...
write_csv(por_transparencia$data[[8]], por_transparencia$caminho[[8]])
```

Isso é um pouco diferente dos nossos usos anteriores de `map()` porque há dois argumentos que estão mudando, não apenas um.
Isso significa que precisamos de uma nova função: `map2()`, que varia o primeiro e o segundo argumentos.
E porque novamente não nos importamos com a saída, queremos `walk2()` em vez de `map2()`.
Isso nos dá:

```{r}
walk2(por_transparencia$data, por_transparencia$caminho, write_csv)
```

```{r}
#| include: false
unlink(por_transparencia$caminho)
```

### Salvando gráficos

Podemos adotar a mesma abordagem básica para criar muitos gráficos.
Vamos primeiro criar uma função que desenhe o gráfico que queremos:

```{r}
#| fig-alt: |
#|   Histograma de quilates de diamantes do conjunto de dados por_transparencia, variando de 
#|   0 a 5 quilates. A distribuição é unimodal e assimétrica à direita com um pico 
#|   em torno de 1 quilate.

quilate_histograma <- function(df) {
  ggplot(df, aes(x = quilate)) + geom_histogram(binwidth = 0.1)  
}

quilate_histograma(por_transparencia$data[[1]])
```

Agora podemos usar `map()` para criar uma lista de muitos gráficos[^iteration-7] e seus eventuais caminhos de arquivo:

[^iteration-7]: Você pode imprimir `por_transparencia$grafico` para obter uma animação bruta --- você obterá um gráfico para cada elemento de `graficos`.
    NOTA: isso não aconteceu comigo.

```{r}
por_transparencia <- por_transparencia |> 
  mutate(
    grafico = map(data, quilate_histograma),
    caminho = str_glue("transparencia-{transparencia}.png")
  )
```

Em seguida, use `walk2()` com `ggsave()` para salvar cada gráfico:

```{r}
walk2(
  por_transparencia$caminho,
  por_transparencia$grafico,
  \(caminho, grafico) ggsave(caminho, grafico, width = 6, height = 6)
)
```

Isto é um atalho para:

```{r}
#| eval: false
ggsave(por_transparencia$caminho[[1]], por_transparencia$grafico[[1]], width = 6, height = 6)
ggsave(por_transparencia$caminho[[2]], por_transparencia$grafico[[2]], width = 6, height = 6)
ggsave(por_transparencia$caminho[[3]], por_transparencia$grafico[[3]], width = 6, height = 6)
...
ggsave(por_transparencia$caminho[[8]], por_transparencia$grafico[[8]], width = 6, height = 6)
```

```{r}
#| include: false
unlink(por_transparencia$caminho)
```

```{=html}
<!-- 
### Exercícios

1.  Imagine que você tem uma tabela de dados de alunos contendo (entre outras variáveis) `nome_escola` e `id_estudante`. Esboce o código que você escreveria se quisesse salvar todas as informações de cada aluno em um arquivo chamado `{id_estudante}.csv` no diretório `{escola}`.
-->
```
## Resumo

Neste capítulo, você viu como usar a iteração explícita para resolver três problemas que surgem frequentemente ao fazer ciência de dados: manipular múltiplas colunas, ler vários arquivos e salvar múltiplas saídas.
Mas, em geral, a iteração é um superpoder: se você conhece a técnica de iteração correta, pode facilmente passar da solução de um problema para a solução de todos os problemas.
Depois de dominar as técnicas deste capítulo, é altamente recomendável aprender mais lendo o [capítulo Funcionais](https://adv-r.hadley.nz/funcionals.html) do *R Avançado* e consultando o [site do pacote purrr](https://purrr.tidyverse.org).

Se você sabe muito sobre iteração em outras linguagens, pode se surpreender por não termos discutido o loop `for`.
Isso ocorre porque a orientação do R em relação à análise de dados muda a forma como iteramos: na maioria dos casos, você pode confiar em um idioma existente para fazer algo em cada coluna ou grupo.
E quando não puder, muitas vezes você pode usar uma ferramenta de programação funcional como `map()` que faz algo para cada elemento de uma lista.
No entanto, você verá loops `for` em códigos por aí, então aprenderá sobre eles no próximo capítulo, onde discutiremos algumas ferramentas importantes do R base.
