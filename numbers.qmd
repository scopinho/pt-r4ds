# Números {#sec-numbers}

```{r}
#| echo: false
#| results: asis

source("_common.R")
```

## Introdução

Vetores numéricos são a espinha dorsal da ciência de dados e você já os usou muitas vezes anteriormente neste livro.
Agora é hora de pesquisar sistematicamente o que você pode fazer com eles em R, garantindo que você esteja bem situado para resolver qualquer problema futuro envolvendo vetores numéricos.

Começaremos fornecendo algumas ferramentas para criar números se você tiver textos (*strings*) e depois entraremos em mais detalhes sobre `count()`.
Em seguida, mergulharemos em várias transformações numéricas que combinam bem com `mutate()`, incluindo transformações mais gerais que podem ser aplicadas a outros tipos de vetores, mas são frequentemente usadas com vetores numéricos.
Terminaremos abordando as funções de sumarização que combinam bem com `summarize()` e mostraremos como elas também podem ser usadas com `mutate()`.

### Pré-requisitos

Este capítulo usa principalmente funções do R base que estão disponíveis sem precisarmos carregar nenhum pacote.
Mas ainda iremos carregar o pacote tidyverse pois usaremos estas funções do R base dentro de funções do tidyverse como `mutate()` e `filter()`.
Como no capítulo anterior, usaremos exemplos reais do pacote dados, bem como exemplos simples feitos com `c()` e `tribble()`.

```{r}
#| label: setup
#| message: false

library(tidyverse)
library(dados)
```

## Criando números

Na maioria dos casos, você obterá números já registrados em um dos dois tipos do R: inteiro (*integer*) ou ponto-flutuante (*double*), .
Em alguns casos, você irá encontrá-los como textos (*strings*), possivelmente porque você os criou com pivotagem (*pivoting*) de algum cabeçalho de coluna ou porque algo deu errado em seu processo de importação.

O pacote readr fornece duas funções úteis para transformar *strings* em números: `parse_double()` e `parse_number()`.
Use `parse_double()` quando possuir números que foram escritos como *strings*:

```{r}
x <- c("1.2", "5.6", "1e3")
parse_double(x)
```

Use `parse_number()` quando possuir *strings* que contenham textos não numéricos que você deseja ignorar.
Isto é particularmente útil para dados de moedas e porcentagens:

```{r}
x <- c("$1,234", "USD 3,513", "59%")
parse_number(x)
```

## Contagens {#sec-counts}

É uma supresa o quanto de ciência de dados você pode fazer somente com um pouco de contagem e aritmética básica, então o pacote dplyr torna a contagem o mais fácil possível com `count()`.
Esta função é ótima para explorações rápidas e validações durante a análise:

```{r}
voos |> count(destino)
```

(Independente do conselho no @sec-workflow-style, normalmente colocamos `count()` em uma única linha, pois é usado geralmente em linha de comando (*console*) para uma rápida verificação que um cálculo está funcionando como esperado.)

Se você quiser os valores mais comuns, adicione `sort = TRUE`:

```{r}
voos |> count(destino, sort = TRUE)
```

E lembre-se que, se você quiser ver todos os valores, você pode usar `|> View()` ou `|> print(n = Inf)`.

Você pode fazer o mesmo cálculo "na mão" com `group_by()`, `summarize()` e `n()`.
Isto é útil pois permite que você faça outras sumarizações ao mesmo tempo:

```{r}
voos |> 
  group_by(destino) |> 
  summarize(
    n = n(),
    atraso = mean(atraso_chegada, na.rm = TRUE)
  )
```

`n()` é uma função de sumarização especial que não recebe nenhum argumento, mas ao invés disso, acessa informação sobre o grupo "atual".
Isto significa que funciona apenas dentro de verbos dplyr:

```{r}
#| error: true

n()
```

Existem algumas variações de `n()` e `count()` que você deve achar útil:

-   `n_distinct(x)` conta o número de valores distintos (únicos) de uma ou mais variáveis.
    Por exemplo, poderíamos obter quais destinos são mais oferecidos por companhia aérea:

    ```{r}
    voos |> 
      group_by(destino) |> 
      summarize(companhia_aerea = n_distinct(companhia_aerea)) |> 
      arrange(desc(companhia_aerea))
    ```

-   Uma contagem ponderada (*weigthed count*) é uma soma.
    Pode exemplo, você poderia "contar" o número de milhas que cada avião voou:

    ```{r}
    voos |> 
      group_by(codigo_cauda) |> 
      summarize(milhas = sum(distancia))
    ```

    Contagem ponderada é um problema tão comum que `count()` tem um argumento `wt` que faz a mesma coisa:

    ```{r}
    #| results: false
    voos |> count(codigo_cauda, wt = distancia)
    ```

-   Você pode contar valores faltantes (*missing values*) combinando `sum()` e `is.na()`.
    No conjunto de dados `voos` isto representa os voos cancelados:

    ```{r}
    voos |> 
      group_by(destino) |> 
      summarize(num_cancelados = sum(is.na(horario_saida))) 
    ```

### Exercícios

1.  Como você pode usar `count()` para contar o número de linhas com valores faltantes de uma determinada variável?
2.  Expanda as seguintes chamadas `count()` para usar `group_by()`, `summarize()` e `arrange()` ao invés de `count()`:
    1.  `flights |> count(dest, sort = TRUE)`

    2.  `flights |> count(tailnum, wt = distance)`

## Transformações numéricas

Funções de transformação trabalham bem com `mutate()` porque suas saídas são do mesmo tamanho que suas entradas.
A grande maioria das funções de transformação já fazem parte do R base.
É impraticável listar todas, portanto esta seção irá mostrar as mais úteis.
Como um exemplo, enquanto o R fornece todas as funções trigonemétricas que você pode sonhar, não iremos listá-las aqui pois elas são raramente necessárias em ciência de dados.

### Regras aritméticas e de reciclagem {#sec-recycling}

Introduzimos a base da aritmética (`+`, `-`, `*`, `/`, `^`) no @sec-workflow-basics e desde então a temos usado muito.
Estas funções não precisam de muitas explicações pois elas fazem o que você aprendeu na escola primária.
Mas temos que falar brevemente sobre **regras de reciclagem** (*recycling rules*) que determinam o que ocorre quando os lados direito e esquerdo tem tamanhos diferentes.
Isto é importante para operações como `voos |> mutate(tempo_voo = tempo_voo / 60)` pois existem 336.776 números do lado esquerdo da `/` mas apenas um no lado direito.

O R lida com tamanhos incompatíveis (*mismatched lengths*) com **reciclagem** ou repetição, do vetor menor.
Podemos ver isso mais facilmente se criarmos vetores fora de um *data frame*:

```{r}
x <- c(1, 2, 10, 20)
x / 5
# é um atalho para
x / c(5, 5, 5, 5)
```

Geralmente, você quer reciclar apenas números únicos (i.e. vetores de tamanho 1), mas o R irá reciclar qualquer vetor de menor tamanho.
Em geral (mas nem sempre), o R te retorna uma mensagem de aviso se o vetor maior não é um múltiplo do menor:

```{r}
x * c(1, 2)
x * c(1, 2, 3)
```

Estas regras de reciclagem se aplicam também a comparações lógicas (`==`, `<`, `<=`, `>`, `>=`, `!=`) e podem levar à resultados surpreendentes se você acidentalmente usar `==` ao invés de `%in%` e o *data frame* tiver um número lamentável de linhas.
Por exemplo, veja este código que tenta encontrar todos os voos de Janeiro e Fevereiro:

```{r}
voos |> 
  filter(mes == c(1, 2))
```

O código é executado sem erros, mas não retorna o que você espera.
Devido às regras de reciclagem, ele encontra um número ímpar de linhas que saíram em Janeiro e um número par de voos que saíram em Fevereiro.
E infelizmente, não há aviso de erro, pois `voos` possui um número par de linhas.

Para te proteger desse tipo de falha silenciosa, a maioria das funções do tidyverse usa um forma restrita de reciclagem que recicla apenas valores únicos.
Infelizmente isto não ajuda aqui, ou em vários outros casos, pois o cálculo é feito pela função `==` do R base e não pela `filter()`.

### Mínimo e máximo

As funções aritméticas trabalham com pares de variáveis.
Duas funções intimamente relacionadas são `pmin()` e `pmax()`, que quando dadas duas ou mais variáveis ​​retornarão o menor ou maior valor em cada linha:

```{r}
df <- tribble(
  ~x, ~y,
  1,  3,
  5,  2,
  7, NA,
)

df |> 
  mutate(
    min = pmin(x, y, na.rm = TRUE),
    max = pmax(x, y, na.rm = TRUE)
  )
```

Observe que elas são diferentes das funções de sumarização `min()` e `max()` que recebem múltiplas observações e retornam um único valor.
Você pode dizer quando usou a forma errada quando todos os mínimos e todos os máximos têm o mesmo valor:

```{r}
df |> 
  mutate(
    min = min(x, y, na.rm = TRUE),
    max = max(x, y, na.rm = TRUE)
  )
```

### Aritmética modular

Artitmética modular é o termo técnico para o tipo de matemática que você fez quando aprendeu sobre casas decimais, e.x. divisão que retornam um valor inteiro e um resto.
No R, `%/%` faz uma divisão inteira e `%%` calcula o resto:

```{r}
1:10 %/% 3
1:10 %% 3
```

Aritmética modular é útil para o conjunto de dados `voos`, pois podemos usá-la para quebrar a variável `saida_programada` em `hora` e `minuto`:

```{r}
voos |> 
  mutate(
    hora = saida_programada %/% 100,
    minuto = saida_programada %% 100,
    .keep = "used"
  )
```

Podemos combinar isto com o truque `mean(is.na(x))` da @sec-logical-summaries para ver como a proporção de voos cancelados varia ao longo do dia.
Os resultados são mostrados na @fig-prop-cancelled.

```{r}
#| label: fig-prop-cancelled
#| fig-cap: | 
#|   Um gráfico de linha com hora da saída programada no eixo-x e a proporção 
#|   dos voos cancelados no eixo-y. Cancelamentos parecem se acumular
#|   ao longo do dia até as 20:00 horas, voos noturnos parecem ter muito menos chances
#|   de serem cancelados.
#| fig-alt: |
#|   Um gráfico de linha mostrando como a proporção de voos cancelados muda 
#|   ao longo do dia. A proporção começa baixa, de aproximadamente 0.5% às 06:00 horas 
#|   e então aumenta de forma uniforme ao longo do dia até um pico 
#|   de 4% às 19:00m horas. A proporção de voos cancelados então cai rapidamente
#|   chegando a aproximadamente 1% à meia-noite.
voos |> 
  group_by(hora = saida_programada %/% 100) |> 
  summarize(prop_cancelados = mean(is.na(horario_saida)), n = n()) |> 
  filter(hora > 1) |> 
  ggplot(aes(x = hora, y = prop_cancelados)) +
  geom_line(color = "grey50") + 
  geom_point(aes(size = n))
```

### Logaritmos

Logaritmos são transformações incríveis para lidar com dados que variam em múltiplas ordens de magnitude e também para converter o crescimento exponencial em crescimento linear.
No R, você tem escolha de três logaritmos: `log()` (o logaritmo natural, base e), `log2()` (base 2), e `log10()` (base 10).
Recomendamos usar `log2()` ou `log10()`.
`log2()` é fácil interpretar pois a diferença de 1 na escala logarítmica corresponde ao dobro na escalada original e a diferença de -1 corresponde à metade; e o `log10()` é de fácil transformação inversa (*back-transform*) (e.x.) 3 é 10\^3 = 1000.
O inverso de `log()` é `exp()`; para calcular o inverso de `log2()` ou `log10()` você precisará usar `2^` ou `10^`.

### Arredondamento {#sec-rounding}

Use `round(x)` para arredondar um número para o inteiro mais próximo:

```{r}
round(123.456)
```

Você pode controlar a precisão do arredondamento usando o segundo argumento, `digits`.
`round(x, digits)` arredonda para o próximo `10^-n` então `digits = 2` irá arredondar para o 0.01 mais próximo.
Esta definição é útil, pois implica que `round(x, -3)` arredondará para o milésimo mais próximo, o que de fato acontece:

```{r}
round(123.456, 2)  # dois dígitos
round(123.456, 1)  # um dígito
round(123.456, -1) # arredonda para dezena mais próxima
round(123.456, -2) # arredonda para a centena mais próxima
```

Há algo de estranho com `round()` que parece uma surpresa à primeira vista:

```{r}
round(c(1.5, 2.5))
```

`round()` usa o que é conhecido como "arredondamento da metade para o par" ou arredondamento do banqueiro: se um número estiver no meio do caminho entre dois inteiros, ele será arredondado para o inteiro **par**.
Esta é uma boa estratégia porque mantém o arredondamento imparcial: metade de todos os 0,5 são arredondados para cima e a outra metade para baixo.

`round()` é acompanhada por `floor()` que sempre arredonda para baixo e `ceiling()` que sempre arredonda para cima:

```{r}
x <- 123.456

floor(x)
ceiling(x)
```

Estas funções não possuem o argumento `digits`, portanto você deve escalar para baixo, arredondar e depois escalar para cima:

```{r}
# Arredonda para baixo para os dois dígitos mais próximos
floor(x / 0.01) * 0.01
# Arredonda para cima para os dois dígitos mais próximos
ceiling(x / 0.01) * 0.01
```

Você pode usar a mesma técnica com `round()` para arredondar para múltiplos de algum número:

```{r}
# Arredonda para o múltiplo de 4 mais próximo
round(x / 4) * 4

# Arredonda para o 0.25 mais próximo
round(x / 0.25) * 0.25
```

### Separando (*cuttting*) números em intervalos

Use `cut()`[^numbers-1] para separar um vetor numérico em intervalos (também chamadas de *bin*) discretos:

[^numbers-1]: ggplot2 oferece funções de ajuda para casos comuns como `cut_interval()`, `cut_number()` e `cut_width()`.
    ggplot2 é um lugar reconhecidamente estranho para manter essas funções, mas elas são úteis como parte do cálculo do histograma e foram escritas antes de qualquer outra parte do tidyverse existir.

```{r}
x <- c(1, 2, 5, 10, 15, 20)
cut(x, breaks = c(0, 5, 10, 15, 20))
```

As quebras (`breaks`) não precisam ser espaçadas igualmente:

```{r}
cut(x, breaks = c(0, 5, 10, 100))
```

Você pode, opcionalmente, definir seus próprios rótulos (`labels`).
Note que deve haver um `labels` a menos que o número de `breaks`.

```{r}
cut(x, 
  breaks = c(0, 5, 10, 15, 20), 
  labels = c("sm", "md", "lg", "xl")
)
```

Qualquer valor fora do intervalo de quebras, se torna automaticamente `NA`:

```{r}
y <- c(NA, -10, 5, 10, 30)
cut(y, breaks = c(0, 5, 10, 15, 20))
```

Veja a documentação para outros argumentos úteis como `right` e `include.lowest`, que controlam se os intervalos são `[a, b)` ou `(a, b]` e se o intervalor mais baixo deve ser `[a, b]`.

### Agregadores cumulativos e rolantes {#sec-cumulative-and-rolling-aggregates}

O R base oferece `cumsum()`, `cumprod()`, `cummin()`, `cummax()` para somas, produtos, mínimos e máximos contínuos ou cumulativos.
dplyr oferece `cummean()` para média cumulativa (um tipo de média móvel).
Somas acumuladas tendem a ser de maior uso na prática:

```{r}
x <- 1:10
cumsum(x)
```

Se você precisar de agregadores cumulativos ou rolantes mais complexos, experimente o pacote [slider](https://slider.r-lib.org/).

### Exercícios

1.  Explique o que cada linha de código usada para gerar a @fig-prop-cancelled faz.

2.  Quais funções de trigonometria o R oferece?
    Adivinhe alguns nomes e veja a documentação.
    Elas usam graus ou radianos?

3.  Atualmente `horario_saida` e `saida_programada` são convenientes para consultá-las, mas difícil de calculá-las pois elas não são realmente números contínuos.
    Você pode ver o problema básico executando o código abaixo: há um intervalo entre cada hora.

    ```{r}
    #| eval: false
    voos |> 
      filter(mes == 1, dia == 1) |> 
      ggplot(aes(x = saida_programada, y = atraso_saida)) +
      geom_point()
    ```

    Converta estas variáveis para uma representação real de tempo (em frações de hora ou minutos a partir da meia-noite).

4.  Arredonde `horario_saida` e `horario_chegada` para os cinco minutos mais próximos.

## Transformações gerais

A seção seguinte descreve algumas transformações gerais que são frequentemente usadas em vetores numéricos, mas podem ser usadas em outros tipos de colunas.

### Ranqueamento (*rank*)

O dplyr oferece diversas funções de ranqueamento inspiradas no SQL, mas você deve sempre começar com `dplyr::min_rank()`.
Ela usa o método típico para lidar com empates, e.x., 1o, 2o, 2o, 4o.

```{r}
x <- c(1, 2, 2, 3, 4, NA)
min_rank(x)
```

Note que o valor mais baixo tem o menor ranqueamento; use `desc(x)` para dar aos maiores valores o menor ranqueamento:

```{r}
min_rank(desc(x))
```

Caso `min_rank()` não fizer o que você deseja, então veja as variantes `dplyr::row_number()`, `dplyr::dense_rank()`, `dplyr::percent_rank()` e `dplyr::cume_dist()`.
Veja a documentação para mais detalhes.

```{r}
df <- tibble(x = x)
df |> 
  mutate(
    num_linha = row_number(x),
    ranqueamento_dense = dense_rank(x),
    ranqueamento_percentual = percent_rank(x),
    distrib_cumulativa = cume_dist(x)
  )
```

Você pode chegar nos mesmos resultados selecionando o argumento `ties.method` adequado na `rank()` do R base; você provavelmente desejará definir `na.last = "keep"` para manter `NA`s como `NA`.

`row_number()` também pode ser usada sem nenhum argumento dentro de um verbo dplyr.
Neste caso, irá te retornar o número da linha "atual".
Quando combinado com `%%` ou `%/%`, pode ser uma ferramenta útil para dividir os dados em grupos de tamanhos parecidos:

```{r}
df <- tibble(id = 1:10)

df |> 
  mutate(
    linha_0 = row_number() - 1,
    tres_grupos = linha_0 %% 3,
    tres_em_cada_grupo = linha_0 %/% 3
  )
```

### Deslocamentos (*offsets*)

`dplyr::lead()` e `dplyr::lag()` permitem que você consulte os valores imediatamente antes ou logo após o valor "atual".
Elas retornam um vetor do mesmo comprimento da entrada, preenchido com `NA`s no início ou no final:

```{r}
x <- c(2, 5, 11, 11, 19, 35)
lag(x)
lead(x)
```

-   `x - lag(x)` fornece a diferença entre o valor atual e o anterior.

    ```{r}
    x - lag(x)
    ```

-   `x == lag(x)` informa quando o valor atual muda.

    ```{r}
    x == lag(x)
    ```

Você pode determinar o número de posições para frente (*lead*) ou para trás (*lag*) usando o segundo argumento `n`.

### Identificadores consecutivos

Às vezes você deseja iniciar um novo grupo sempre que algum evento ocorrer.
Por exemplo, quando você analisa dados de um site, é comum querer dividir os eventos em sessões, onde você inicia uma nova sessão após um intervalo de mais de `x` minutos desde a última atividade.
Por exemplo, imagine que você tenha os horários em que alguém visitou um site:

```{r}
eventos <- tibble(
  horario = c(0, 1, 2, 3, 5, 10, 12, 15, 17, 19, 20, 27, 28, 30)
)

```

E você calculou o período entre cada ocorrência de eventos, e descobriu se há um intervalo grande o suficiente para se qualificar:

```{r}
eventos <- eventos |> 
  mutate(
    diferenca = horario - lag(horario, default = first(horario)),
    tem_intervalo_grande = diferenca >= 5
  )
eventos
```

Mas como podemos ir deste vetor lógico para algo que podemos agrupar com `group_by()`?
`cumsum()`, da  @sec-cumulative-and-rolling-aggregates, vem pra ajudar com intervalos (*gaps*), e.x. `tem_intervalo_grande` como `TRUE`, irá incrementar `grupo` em um (@sec-numeric-summaries-of-logicals):

```{r}
eventos |> mutate(
  grupo = cumsum(tem_intervalo_grande)
)
```

Outra abordagem para criar variáveis de grupo é `consecutive_id()`, que inicia um novo grupo toda vez que algum de seus argumentos muda.
Por exemplo, inspirado [nesta pergunta do stackoverflow](https://stackoverflow.com/questions/27482712), imagine que você tenha um *data frame* com vários valores repetidos:

```{r}
df <- tibble(
  x = c("a", "a", "a", "b", "c", "c", "d", "e", "a", "a", "b", "b"),
  y = c(1, 2, 3, 2, 4, 1, 3, 9, 4, 8, 10, 199)
)
```

Se você quer manter a primeira linha para cada `x`repetido, você pode usar `group_by()`, `consecutive_id()` e `slice_head()`:

```{r}
df |> 
  group_by(id = consecutive_id(x)) |> 
  slice_head(n = 1)
```

### Exercícios

1.  Encontre os 10 voos mais atrasados ​​usando uma função de ranqueamento.
    Como você quer lidar com os empates?
    Leia atentamente a documentação da `min_rank()`.

2.  Qual avião (`codigo_cauda`) tem o pior histórico de pontualidade?

3.  Em qual horário você deve voar se quiser evitar atrasos o máximo possível?

4.  O que faz `voos |> group_by(destino) |> filter(row_number() < 4)` ?
    O que faz `voos |> group_by(destino) |> filter(row_number(atraso_saida) < 4)` ?

5.  Para cada destino, calcule o total de minutos de atraso.
    Para cada voo, calcule a proporção do atraso total para o seu destino.

6.  Os atrasos são normalmente correlacionados temporalmente: mesmo depois de o problema que causou o atraso inicial ter sido resolvido, os voos posteriores são atrasados ​​para permitir a saída dos voos anteriores.
    Usando `lag()`, explore como o atraso médio do voo de uma hora está relacionado ao atraso médio da hora anterior..

    ```{r}
    #| results: false

    voos |> 
      mutate(hora = horario_saida %/% 100) |> 
      group_by(ano, mes, dia, hora) |> 
      summarize(
        atraso_saida = mean(atraso_saida, na.rm = TRUE),
        n = n(),
        .groups = "drop"
      ) |> 
      filter(n > 5)
    ```

7.  Veja cada destino.
    Você consegue encontrar voos suspeitosamente rápidos (ou seja, voos que representam um possível erro de entrada de dados)?
    Calcule o tempo de viagem de um voo em relação ao voo mais curto para esse destino.
    Quais voos tiveram mais atrasos no ar?

8.  Encontre todos os destinos operados por pelo menos duas companhias aéreas.
    Use esses destinos para chegar a um ranqueamento relativo das transportadoras com base no seu desempenho para o mesmo destino.

## Sumarização numérica

Apenas usar as contagens, médias e somas que já apresentamos pode ajudar você a percorrer um longo caminho, mas o R fornece muitas outras funções de úteis de sumarização.
Aqui está uma seleção que você pode achar útil.

### Centro

Até agora, na maioria da vezes, usamos a média com `mean()` para sumarizar o centro de um vetor de valores.
Como vimos na @sec-sample-size, uma vez que a média é a soma dividida pela contagem, ela é sensível até mesmo por um pequeno número de valores muito altos ou muito baixos.
Uma alternativa é usar a mediana, com `median()`, que encontra o valor que se encontra no "meio" do vetor, e.x. 50% dos valores estão acima e 50% estão abaixo.
Dependendo da forma da distribuição da variável de interesse, média ou mediana podem ser uma melhor medida de posição.
Por exemplo, para distribuições simétricas, geralmente reportamos a média, enquanto para distribuições assimétricas (*skewed*), geralmente reportamos a mediana.

A @fig-mean-vs-median compara a média e a mediana dos valores de atraso na saída (em minutos) para cada destino.
A mediana de atraso é sempre menor que a média de atraso, pois em alguns casos, os voos saem com várias horas de atraso, mas nunca saem várias horas antecipadamente.

```{r}
#| label: fig-mean-vs-median
#| fig-cap: |
#|   Um gráfico de dispersão mostrando a diferença entre sumarizar atraso das saídas diárias
#|   com mediana ao invés da média.
#| fig-alt: |
#|   Todos os pontos estão sob a linha de 45°, signifcando que o atraso da mediana é
#|   sempre menor que o atraso médio. A maioria dos pontos estão agrupados em um
#|   região densa da média [0, 20] e mediana [0, 5]. Conforme o atraso médio aumenta,
#|   a dispersão da mediana também aumenta. Existem dois pontos discrepantes
#|   com média ~60, mediana ~50 e média ~85, mediana ~55.
voos |>
  group_by(ano, mes, dia) |>
  summarize(
    media = mean(atraso_saida, na.rm = TRUE),
    mediana = median(atraso_saida, na.rm = TRUE),
    n = n(),
    .groups = "drop"
  ) |> 
  ggplot(aes(x = media, y = mediana)) + 
  geom_abline(slope = 1, intercept = 0, color = "white", linewidth = 2) +
  geom_point()
```

Você também pode estar se perguntando sobre a **moda**, ou valor mais comum (ou mais frequente).
Esta é uma medida que funciona bem apenas para casos muito simples (que pode ser a razão que você aprendeu sobre ela na escola primária), mas não funciona bem para conjuntos de dados reais.
Se o dados forem discretos, podem existir muitos valores comuns, e se os dados forem contínuos, podem não existir valores comuns pois cada valor é ligeiramente diferente um do outro.
Por estas razões, a moda tende a não ser usada por estatísticos e não há uma função de moda no R básico[^numbers-2].

[^numbers-2]: A função `mode()` faz algo um pouco diferente!

### Minimos, maximos e quantis {#sec-min-max-summary}

E se você tiver interesse em saber as posições diferentes do centro?
`min()` e `max()` te darão os menores e maiores valores.
Uma outra poderosa ferramenta é a `quantile()` que é uma generalização da mediana: `quantile(x, 0.25)` retorna o valor de `x` que é maior que 25% dos valores, `quantile(x, 0.5)` é equivalente à mediana e `quantile(x, 0.95)` retornará o valor que é maior que 95% dos valores.

Para os dados de `voos`, você pode querer olhar no quantil 95% dos voos em atraso ao invés do valor máximo, pois isto ignora os voos com maior atraso, os quais podem ser muito extremos.

```{r}
voos |>
  group_by(ano, mes, dia) |>
  summarize(
    max = max(atraso_saida, na.rm = TRUE),
    q95 = quantile(atraso_saida, 0.95, na.rm = TRUE),
    .groups = "drop"
  )
```

### Dispersão

Algumas vezes você não tem interesse em onde a maior parte dos dados se encontra, mas sim como estão dispersos.
Duas medidas de dispersão muito usadas são, o desvio padrão, `sd(x)`, e o intervalo interquartil (*inter-quartile range*), `IQR()`.
Não iremos explicar o `sd()` aqui, pois você já deve ser algo familiar a você, mas `IQR()` pode ser algo novo, --- ele é `quantile(x, 0.75) - quantile(x, 0.25)` e retornar um intervalo que contém a metade (50%) dos dados.

Podemos usar isso para revelar uma pequena estranheza nos dados dos `voos`.
Você poderia esperar que a dispersão da distância entre a origem e o destino fosse zero, uma vez que os aeroportos estão sempre no mesmo lugar.
Mas o código abaixo revela uma estranheza nos dados do aeroporto [EGE](https://en.wikipedia.org/wiki/Eagle_County_Regional_Airport):

```{r}
voos |> 
  group_by(origem, destino) |> 
  summarize(
    distancia_sd = IQR(distancia), 
    n = n(),
    .groups = "drop"
  ) |> 
  filter(distancia_sd > 0)
```

### Distribuições

Vale lembrar que todas as estatísticas de sumarização descritas acima são uma forma de reduzir a distribuição a um único número.
Isso significa que eles são fundamentalmente redutores e, se você escolher a sumarização errada, poderá facilmente perder diferenças importantes entre os grupos.
É por isso que é sempre uma boa ideia visualizar a distribuição antes de se comprometer com suas estatísticas de sumarização.

A @fig-flights-dist mostra a distribuição geral dos atrasos nas saídas.
A distribuição é tão distorcida que precisamos ampliar para ver a maior parte dos dados.
Isto sugere que é pouco provável que a média seja um bom resumo e que poderíamos preferir a mediana.

```{r}
#| echo: false
#| label: fig-flights-dist
#| fig-cap: |
#|   (Esquerda) O histograma dos dados completos é extremamente distorcido, tornando-o
#|   difícil obter detalhes. (Direita) Focar nos atrasos de menos de duas
#|   horas torna possível ver o que está acontecendo com a maior parte das
#|   observações.
#| fig-alt: |
#|   Dois histogramas de `atraso_saida`. À esquerda, é muito difícil ver
#|   qualquer padrão, exceto que há um pico muito grande em torno de zero, as barras
#|   diminuem rapidamente de altura e, na maior parte do gráfico, você não consegue
#|   ver nenhuma barra porque elas são muito curtas para serem vistas. À direita,
#|   onde descartamos atrasos superiores a duas horas, podemos ver
#|   que o pico ocorre ligeiramente abaixo de zero (ou seja, a maioria dos
#|   voos saia alguns minutos mais cedo), mas ainda há uma queda acentuada
#|   depois disso.
#| fig-asp: 0.5

library(patchwork)

todos <- voos |>
  ggplot(aes(x = atraso_saida)) + 
  geom_histogram(binwidth = 15, na.rm = TRUE)

atraso120 <- flights |>
  filter(atraso_saida < 120) |> 
  ggplot(aes(x = atraso_saida)) + 
  geom_histogram(binwidth = 5)

todos + atraso120
```

Também é uma boa ideia verificar se as distribuições dos subgrupos se assemelham ao todo.
No gráfico a seguir, 365 polígonos de frequência de `atraso_saida`, um para cada dia, são sobrepostos.
As distribuições parecem seguir um padrão comum, sugerindo que não há problema em usar a mesma sumarização para cada dia.

```{r}
#| fig-alt: |
#|   A distribuição de `atraso_saida` é altamente distorcida para a direita com um forte
#|   pico ligeiramente menor que 0. Os polígonos de 365 frequências estão em sua maioria
#|   sobrepondo-se formando uma camada preta espessa e sem graça.

voos |>
  filter(atraso_saida < 120) |> 
  ggplot(aes(x = atraso_saida, group = interaction(dia, mes))) + 
  geom_freqpoly(binwidth = 5, alpha = 1/5)
```

Não tenha medo de explorar suas próprias sumarizações personalizadas especificamente adaptadas aos dados com os quais você está trabalhando.
Nesse caso, isso pode significar resumir separadamente os voos que partiram mais cedo versus os voos que partiram tarde, ou dado que os valores estão muito distorcidos, você pode tentar uma transformação logarítmica.
Por fim, não esqueça o que você aprendeu na @sec-sample-size: sempre que criar sumarizações numéricas, é uma boa ideia incluir o número de observações em cada grupo.

### Posições

Há um último tipo de sumarização útil para vetores numéricos, que também funciona para outros tipos de valores: extrair um valor em uma posição específica: `first(x)`, `last(x)` e `nth(x, n)`.

Por exemplo, podemos encontrar a primeira e última saída em cada dia:

```{r}
voos |> 
  group_by(ano, mes, dia) |> 
  summarize(
    primeira_saida = first(horario_saida, na_rm = TRUE), 
    quinta_saida = nth(horario_saida, 5, na_rm = TRUE),
    ultima_saida = last(horario_saida, na_rm = TRUE)
  )
```

(NB: Uma vez que as funções do dplyr usam `_` para separar componentes da função e nomes de argumentos, estas funções usam `na_rm` ao invés de `na.rm`.)

Se você está familiarizado com `[`, o qual retornaremos na @sec-subset-many, você pode estar se perguntando se você realmente precisa destas funções.
Existem três razões: o argumento `default` permite que você forneça um padrão se a posição especificada não existir, o argumento `order_by` permite que você ordene localmente sobrescrevendo a ordenação das linhas, e o argumento `na_rm` permite você ignorar valores faltantes (*missing values*).

Extrair valores em determinada posição é complementar à filtrar em ranqueamentos.
Filtrar retorna todas as variáveis, com cada observação em uma linha separada:

```{r}
voos |> 
  group_by(ano, mes, dia) |> 
  mutate(r = min_rank(saida_programada)) |> 
  filter(r %in% c(1, max(r)))
```

### Com `mutate()`

Como o nome sugere, funções de sumarização são usadas tipicamente com `summarize()`.
Entretando, devido às regras de reciclagem discutidas na @sec-recycling, elas podem ser usadas também com `mutate()`, particularmente quando você deseja fazer algum tipo de padronização.
Por exemplo:

-   `x / sum(x)` calcula a proporção de um total.
-   `(x - mean(x)) / sd(x)` calcula o *Z-score* (padronização com média 0 e desvio padrão 1).
-   `(x - min(x)) / (max(x) - min(x))` padroniza em intervalo \[0, 1\].
-   `x / first(x)` calcula um índice baseado na primeira observação.

### Exercícios

1.  Pense em pelo menos 5 maneiras diferentes de avaliar as características típicas de atraso de um grupo de voos.
    Quando a `mean()` é útil?
    Quando a `median()` é útil?
    Quando você poderia querer usar alguma outra maneira?
    Você deveria usar atraso_chegada ou atraso_saida?
    Quando você poderia querer usar dados de `dados::avioes`?

2.  Quais destinos apresentam a maior variação na velocidade aérea?

3.  Crie um gráfico para explorar ainda mais as aventuras do EGE.
    Você pode encontrar alguma evidência de que o aeroporto mudou de local?
    Você pode encontrar outra variável que possa explicar a diferença?

## Resumo

Você já tem familiaridade com muitas ferramentas para trabalhar com números e, depois de ler este capítulo, agora sabe como usá-las no R.
Você também aprendeu algumas transformações gerais úteis que são comumente, mas não exclusivamente, aplicadas a vetores numéricos, como ranqueamentos e deslocamentos.
Por fim, você trabalhou com várias sumarizações numéricas e discutiu alguns dos desafios estatísticos que deveria considerar.

Nos próximos dois capítulos, nos aprofundaremos em *strings* com o pacote stringr.
*Strings* são um grande tópico, então elas têm dois capítulos, um sobre os fundamentos de *strings* e outro sobre expressões regulares (*regex*).
